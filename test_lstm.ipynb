{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "589aa0a4-db52-4075-a8c0-6334f355e607",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Workspace/Users/jorgegarciaotero@gmail.com/tfm_databricks/config/database_connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "689a5a8b-71b8-41e2-bc3d-69e235daa9c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import random\n",
    "import plotly.express as px\n",
    "import joblib\n",
    "from datetime import timedelta\n",
    "from typing import List, Tuple, Dict,Optional\n",
    "\n",
    "# Azure\n",
    "\n",
    "from typing import Tuple, List, Optional\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Models\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,LabelEncoder\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc ,  precision_score, recall_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63253432-3fef-4933-81c5-94d603b2eb73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data(df, targets, scaler_type='standard', drop_cols=['date', 'symbol'], encode_symbol: bool = False):\n",
    "    \"\"\"\n",
    "    Prepares data for ML models by imputing missing values and scaling features.\n",
    "\n",
    "    Args:\n",
    "        - df (pd.DataFrame): Full input DataFrame.\n",
    "        - targets (list): List of target columns.\n",
    "        - scaler_type (str): 'standard' or 'minmax'.\n",
    "        - drop_cols (list): Columns to drop from the DataFrame.\n",
    "        - encode_symbol (bool): Whether to keep and encode 'symbol' as a feature.\n",
    "\n",
    "    Returns:\n",
    "        - df_scaled (pd.DataFrame): Scaled features with targets.\n",
    "        - scaler: The fitted scaler object.\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # Opcionalmente preservar 'symbol' si se desea codificarlo\n",
    "    if encode_symbol and 'symbol' in df_clean.columns:\n",
    "        drop_cols = [col for col in drop_cols if col != 'symbol']\n",
    "\n",
    "    # Eliminar columnas no deseadas\n",
    "    df_clean = df_clean.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "    # Codificar variables categóricas (incluido symbol si se conserva)\n",
    "    for col in df_clean.select_dtypes(include=['object', 'category']).columns:\n",
    "        df_clean[col] = LabelEncoder().fit_transform(df_clean[col].astype(str))\n",
    "\n",
    "    # Separar features y targets\n",
    "    feature_cols = [col for col in df_clean.columns if col not in targets]\n",
    "    X = df_clean[feature_cols]\n",
    "    y = df_clean[targets]\n",
    "\n",
    "    # Imputación de valores\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "    # Escalado\n",
    "    scaler = StandardScaler() if scaler_type == 'standard' else MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "    # Reconstruir DataFrame escalado\n",
    "    df_scaled = pd.DataFrame(X_scaled, columns=feature_cols, index=X.index)\n",
    "\n",
    "    # Agregar los targets de nuevo\n",
    "    df_scaled = pd.concat([df_scaled, y], axis=1)\n",
    "\n",
    "    return df_scaled, scaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b92a3a7-c04b-4199-bfee-e94fd2f7f06a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def model_evaluation(\n",
    "    y_test: pd.Series,\n",
    "    y_pred: pd.Series,\n",
    "    y_prob: pd.Series\n",
    ") -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Evaluates the classification model and plots the metrics\n",
    "    Args:\n",
    "        - y_test (pd.Series): True target vals\n",
    "        - y_pred (pd.Series): Predicted class vals\n",
    "        - y_prov (pd.Series): Predicted probss for clas 1\n",
    "    Returns:\n",
    "        - Tuple[float, float, float]: Accuracy, F1 Score, and ROC AUC.\n",
    "    \"\"\"\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_prob)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    precission = precision_score(y_test, y_pred)\n",
    "    recall= recall_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {roc:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n {cm}\")\n",
    "    print(f\"Precision: {precission:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    cax = ax.matshow(cm, cmap='Blues')\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_xticklabels(['No', 'Yes'])\n",
    "    ax.set_yticklabels(['No', 'Yes'])\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return acc, f1, roc,cm,precission,recall\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cb94290-ed8e-419c-b2c0-9f6742ec8c56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def train_base_lstm_classifier(\n",
    "    df: pd.DataFrame,\n",
    "    target_column: str = 'target_1y',\n",
    "    sequence_length: int = 20,\n",
    "    epochs: int = 100,\n",
    "    batch_size: int = 32,\n",
    "    patience: int = 5,\n",
    "    min_accuracy: float = 0.75  # Accuracy mínima deseada\n",
    "):\n",
    "    \"\"\"\n",
    "    Entrena un modelo base LSTM para clasificación binaria con early stopping.\n",
    "\n",
    "    Returns:\n",
    "        - model: modelo entrenado\n",
    "        - X_test, y_test: conjunto de test\n",
    "        - y_pred_prob, y_pred_class: predicciones\n",
    "    \"\"\"\n",
    "    # Preparar datos\n",
    "    feature_columns = [col for col in df.columns if col != target_column]\n",
    "    data = df[feature_columns + [target_column]].copy()\n",
    "    data[target_column] = (data[target_column] > 0).astype(int)\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data.iloc[i:i + sequence_length, :-1].values)\n",
    "        y.append(data.iloc[i + sequence_length, -1])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, shuffle=False\n",
    "    )\n",
    "\n",
    "    # Modelo LSTM\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=(X.shape[1], X.shape[2]), return_sequences=False))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss=BinaryCrossentropy(),\n",
    "        metrics=['accuracy', AUC()]\n",
    "    )\n",
    "\n",
    "    # Callback para early stopping por valid_accuracy\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=patience,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True,\n",
    "        mode='max'\n",
    "    )\n",
    "\n",
    "    # Entrenar\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluar\n",
    "    y_pred_prob = model.predict(X_test).flatten()\n",
    "    y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "    return model, X_test, y_test, y_pred_prob, y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff2ffc41-6a08-42a9-97d9-5d886599df53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  \"\"\"\n",
    "  columns_to_drop = [\n",
    "      'date', 'symbol', 'capital_gains',\n",
    "      'ret_next_3m', 'ret_next_6m', 'ret_next_1y',\n",
    "      'price_lead_3m', 'price_lead_6m', 'price_lead_1y',\n",
    "      'open_v', 'high', 'low', 'dividends', 'stock_splits',\n",
    "      'is_dividend_day', 'is_stock_split', 'gap_open', 'price_range',\n",
    "      'tr_1', 'tr_2', 'tr_3', 'sma_5', 'bollinger_upper',\n",
    "      'bollinger_lower', 'ema_12', 'macd_line'\n",
    "  ]\n",
    "  print(f\"Shape before: {df.shape}\")\n",
    "  df = df.drop(columns=columns_to_drop, errors='ignore').copy()\n",
    "  numeric_cols = df.select_dtypes(include=[\"float64\", \"int64\", \"int32\"]).columns\n",
    "  imputer = SimpleImputer(strategy=\"mean\")\n",
    "  df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
    "  print(f\"Shape after: {df.shape}\")\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7912bb0-a992-402e-92a7-20939952327c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d913fe4-7c5b-43a3-a035-e9694c08b16c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creates the input widgets and sets the default values\n",
    "dbutils.widgets.text(\"storage_account\", \"smartwalletjorge\", \"Storage Account\")\n",
    "dbutils.widgets.text(\"container\", \"smart-wallet-dl\", \"Container\")\n",
    "dbutils.widgets.text(\"database\", \"smart_wallet\", \"Database\")\n",
    "\n",
    "storage_account = dbutils.widgets.get(\"storage_account\")\n",
    "container = dbutils.widgets.get(\"container\")\n",
    "database_name = dbutils.widgets.get(\"database\")\n",
    "date_value = dbutils.widgets.get(\"date\")\n",
    "if (date_value is None) or (date_value==''):\n",
    "    date_value=None\n",
    "\n",
    "db_connector = DatabaseConnector()\n",
    "print(f\"database_name :{database_name}\")\n",
    "\n",
    "df=db_connector.read_table_from_path(container, database_name, \"stock_data_parquet\", date_value,\"parquet\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "646f7647-03ff-4d85-a9c1-56f490166d43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de7b11d8-eddf-4795-828e-051eb7c68724",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_symbols_df = (\n",
    "    df_full.groupBy(\"symbol\")\n",
    "    .count()\n",
    "    .orderBy(F.desc(\"count\"))\n",
    "    .limit(50)\n",
    ")\n",
    "top_symbols = [row[\"symbol\"] for row in top_symbols_df.collect()]\n",
    "df_clean = df_full.filter(F.col(\"symbol\").isin(top_symbols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07232138-b595-4bb5-adc9-9178629a8c19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_clean.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10a0c3bb-c60b-4209-a307-e35265fdde2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_full[\"target_3m\"] = (df_full[\"ret_next_3m\"] > 0.10).astype(int)\n",
    "df_full[\"target_6m\"] = (df_full[\"ret_next_6m\"] > 0.10).astype(int)\n",
    "df_full[\"target_1y\"] = (df_full[\"ret_next_1y\"] > 0.10).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e52b89ce-8ef7-41b1-bb20-f35bd4a7c49c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46efc157-a6d1-4d09-9902-c487d25adfec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "last_day = df_full['date'].max()\n",
    "df_last = df_full[df_full['date'] == last_day].copy()\n",
    "df_last.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e11f007-4596-42fc-872c-c98dc7208a5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bd794d4-2778-4ad7-b8cb-f4c56823286b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(df_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bed8a805-fc6b-4bf0-b70b-29f4a84e9ff4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_last_clean =clean_columns(df_last)\n",
    "df_last_clean = df_last_clean.drop(columns=['target_3m', 'target_6m', 'target_1y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab4d8e22-78c7-4c54-88d7-2e5d22e6636b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "targets = ['target_3m', 'target_6m', 'target_1y']\n",
    "\n",
    "df_processed_minmax, scaler_minmax = prepare_data(df_clean, targets, scaler_type='minmax', encode_symbol=True)\n",
    "# Entrenar modelo para target_3m\n",
    "model_3m, X_test_3m, y_test_3m, y_prob_3m, y_pred_3m = train_base_lstm_classifier(\n",
    "    df_processed_minmax,\n",
    "    target_column='target_3m'\n",
    ")\n",
    "\n",
    "# Evaluación para target_3m\n",
    "model_evaluation(\n",
    "    y_test=pd.Series(y_test_3m),\n",
    "    y_pred=pd.Series(y_pred_3m),\n",
    "    y_prob=pd.Series(y_prob_3m)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "test_lstm",
   "widgets": {
    "container": {
     "currentValue": "smart-wallet-dl",
     "nuid": "5ab1907a-4f6a-4820-a1bd-83b776f790f5",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "smart-wallet-dl",
      "label": "Container",
      "name": "container",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "smart-wallet-dl",
      "label": "Container",
      "name": "container",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "database": {
     "currentValue": "smart_wallet",
     "nuid": "a6514c90-b072-4fd5-82f0-1ad28733b64a",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "smart_wallet",
      "label": "Database",
      "name": "database",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "smart_wallet",
      "label": "Database",
      "name": "database",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "date": {
     "currentValue": "",
     "nuid": "0ac86826-1ce7-4fb3-b16a-4fbf8b68b7b2",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2024-04-10",
      "label": "Date",
      "name": "date",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2024-04-10",
      "label": "Date",
      "name": "date",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "storage_account": {
     "currentValue": "smartwalletjorge",
     "nuid": "9f3375d3-cda2-411d-a05e-74f39c4948b9",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "smartwalletjorge",
      "label": "Storage Account",
      "name": "storage_account",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "smartwalletjorge",
      "label": "Storage Account",
      "name": "storage_account",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
