{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "1be5d110-6a57-4669-9242-508a6edf5794",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install yfinance\n",
    "%pip install lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "589aa0a4-db52-4075-a8c0-6334f355e607",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Workspace/Users/jorgegarciaotero@gmail.com/config/database_connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6aa3b51-2eb0-40dd-be19-e7719e381cbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Workspace/Users/jorgegarciaotero@gmail.com/config/logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91c0c760-7671-4838-b1b0-808fa57f4f69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import sys\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "import logging\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c08e034-570b-4607-99fe-66b9d719dcaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_price_history(company, ticker, db, first_date, last_date,logger):\n",
    "    '''\n",
    "    Download and process historical stock price data for a given ticker.\n",
    "\n",
    "    Args:\n",
    "        company (yf.Ticker): Yahoo Finance ticker object.\n",
    "        ticker (str): Ticker symbol.\n",
    "        db (Database): Database connection object.\n",
    "        logger (Logger): Logger instance for tracking progress and errors.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    df_hist = company.history(start=first_date, end=last_date)\n",
    "    if not df_hist.empty:\n",
    "        df_hist.reset_index(inplace=True)\n",
    "        df_hist['symbol'] = ticker\n",
    "        df_hist = df_hist.rename(columns=lambda x: str(x).strip().lower().replace(' ', '_'))\n",
    "        df_hist = df_hist.rename(columns={'open': 'open_v', 'close': 'close_v'})\n",
    "        upsert_data(db=db, table_name=\"stock_data\", df=df_hist, pk_columns=[\"date\", \"symbol\"], logger=logger)\n",
    "\n",
    "def process_company_info(company, ticker, db, logger):\n",
    "    '''\n",
    "    Retrieve and process general company information and financial ratios.\n",
    "\n",
    "    Args:\n",
    "        company (yf.Ticker): Yahoo Finance ticker object.\n",
    "        ticker (str): Ticker symbol.\n",
    "        db (Database): Database connection object.\n",
    "        logger (Logger): Logger instance for tracking progress and errors.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    df_info = pd.json_normalize(company.info)\n",
    "    if not df_info.empty:\n",
    "        df_info = df_info.rename(columns={'52WeekChange': 'Week52Change', 'open': 'open_v'})\n",
    "        df_info = df_info.rename(columns=lambda x: str(x).strip().lower().replace(' ', '_'))\n",
    "        df_info['date'] = pd.Timestamp.today().normalize()\n",
    "        if 'companyofficers' in df_info.columns:\n",
    "            df_info = df_info.drop(columns=['companyofficers'])\n",
    "        upsert_data(db=db, table_name=\"company_info\", df=df_info, pk_columns=[\"date\", \"symbol\"], logger=logger)\n",
    "\n",
    "def process_dividends(company, ticker, db, logger):\n",
    "    \"\"\"\n",
    "    Extract historical dividend payments for the specified ticker.\n",
    "    Args:\n",
    "        company (yf.Ticker): Yahoo Finance ticker object.\n",
    "        ticker (str): Ticker symbol.\n",
    "        db (Database): Database connection object.\n",
    "        logger (Logger): Logger instance for tracking progress and errors.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    df_div = company.dividends\n",
    "    if not df_div.empty:\n",
    "        df_div = df_div.to_frame().reset_index()\n",
    "        df_div['symbol'] = ticker\n",
    "        df_div = df_div.rename(columns=lambda x: str(x).strip().lower().replace(' ', '_'))\n",
    "        upsert_data(db=db, table_name=\"dividend_data\", df=df_div, pk_columns=[\"date\", \"symbol\"], logger=logger)\n",
    "\n",
    "def process_splits(company, ticker, db, logger):\n",
    "    \"\"\"\n",
    "    Extract stock split history for the specified ticker.\n",
    "    Args:\n",
    "        company (yf.Ticker): Yahoo Finance ticker object.\n",
    "        ticker (str): Ticker symbol.\n",
    "        db (Database): Database connection object.\n",
    "        logger (Logger): Logger instance for tracking progress and errors.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    df_split = company.splits\n",
    "    if not df_split.empty:\n",
    "        df_split = df_split.to_frame().reset_index()\n",
    "        df_split['symbol'] = ticker\n",
    "        df_split = df_split.rename(columns=lambda x: str(x).strip().lower().replace(' ', '_'))\n",
    "        upsert_data(db=db, table_name=\"split_data\", df=df_split, pk_columns=[\"date\", \"symbol\"], logger=logger)\n",
    "\n",
    "def process_cashflow(company, ticker, db, logger):\n",
    "    \"\"\"\n",
    "    Retrieve and process cash flow statement data for the company.\n",
    "    Args:\n",
    "        company (yf.Ticker): Yahoo Finance ticker object.\n",
    "        ticker (str): Ticker symbol.\n",
    "        db (Database): Database connection object.\n",
    "        logger (Logger): Logger instance for tracking progress and errors.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    df_cf = company.cashflow.T\n",
    "    if not df_cf.empty:\n",
    "        df_cf['symbol'] = ticker\n",
    "        df_cf.reset_index(inplace=True)\n",
    "        df_cf.rename(columns={'index': 'date'}, inplace=True)\n",
    "        df_cf['date'] = pd.to_datetime(df_cf['date'])\n",
    "        df_cf = df_cf.rename(columns=lambda x: str(x).strip().lower().replace(' ', '_'))\n",
    "        upsert_data(db=db, table_name=\"cashflow_data\", df=df_cf, pk_columns=[\"date\", \"symbol\"], logger=logger)\n",
    "\n",
    "def process_recommendations(company, ticker, db, logger):\n",
    "    \"\"\"\n",
    "    Extract analyst recommendations for the company and store them.\n",
    "    Args:\n",
    "        company (yf.Ticker): Yahoo Finance ticker object.\n",
    "        ticker (str): Ticker symbol.\n",
    "        db (Database): Database connection object.\n",
    "        logger (Logger): Logger instance for tracking progress and errors.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    df_reco = company.recommendations\n",
    "    if not df_reco.empty:\n",
    "        df_reco['symbol'] = ticker\n",
    "        df_reco = df_reco.rename(columns=lambda x: str(x).strip().lower().replace(' ', '_'))\n",
    "        df_reco['date'] = pd.Timestamp.today().normalize()\n",
    "        upsert_data(db=db, table_name=\"recommendations_data\", df=df_reco, pk_columns=[\"date\", \"symbol\", \"period\"], logger=logger)\n",
    "\n",
    "def process_balance_sheet(company, ticker, db, logger):\n",
    "    \"\"\"\n",
    "    Retrieve and process balance sheet data for the company.\n",
    "    Args:\n",
    "        company (yf.Ticker): Yahoo Finance ticker object.\n",
    "        ticker (str): Ticker symbol.\n",
    "        db (Database): Database connection object.\n",
    "        logger (Logger): Logger instance for tracking progress and errors.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    df_bs = company.balance_sheet.T\n",
    "    if not df_bs.empty:\n",
    "        df_bs.reset_index(inplace=True)\n",
    "        df_bs['symbol'] = ticker\n",
    "        df_bs = df_bs.rename(columns=lambda x: str(x).strip().lower().replace(' ', '_'))\n",
    "        df_bs.rename(columns={'index': 'date'}, inplace=True)\n",
    "        df_bs['date'] = pd.to_datetime(df_bs['date'])\n",
    "        upsert_data(db=db, table_name=\"balance_sheet_data\", df=df_bs, pk_columns=[\"date\", \"symbol\"], logger=logger)\n",
    "\n",
    "def process_financials(company, ticker, db, logger):\n",
    "    \"\"\"\n",
    "    Retrieve and process the company's income statement data.\n",
    "    Args:\n",
    "        company (yf.Ticker): Yahoo Finance ticker object.\n",
    "        ticker (str): Ticker symbol.\n",
    "        db (Database): Database connection object.\n",
    "        logger (Logger): Logger instance for tracking progress and errors.\n",
    "    Returns:\n",
    "        None\n",
    "        logger (_type_): _description_\n",
    "    \"\"\"\n",
    "    df_fin = company.financials.T\n",
    "    if not df_fin.empty:\n",
    "        df_fin.reset_index(inplace=True)\n",
    "        df_fin['symbol'] = ticker\n",
    "        df_fin = df_fin.rename(columns=lambda x: str(x).strip().lower().replace(' ', '_'))\n",
    "        df_fin.rename(columns={'index': 'date'}, inplace=True)\n",
    "        df_fin['date'] = pd.to_datetime(df_fin['date'])\n",
    "        upsert_data(dvvvvvvvb=db, table_name=\"financial_data\", df=df_fin, pk_columns=[\"date\", \"symbol\"], logger=logger)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6627661a-d4d1-4fdc-bfbc-dc7aa495c4d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def main(first_date,last_date,period):   \n",
    "    logger = get_logger(name=\"my_app\", level=\"INFO\", log_file=\"my_app.log\")\n",
    "    logger.info(\"Starting ...\")   \n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    db =  DatabaseConnector()\n",
    "    df = db.read_table_from_sql(\"company_info\")\n",
    "    total_tickers = df.select(\"symbol\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "    print(f\"Total tickers: {len(total_tickers)}\")\n",
    "    print(len(total_tickers))\n",
    "    #total_tickers=total_tickers[320:1000]\n",
    "    for i, ticker in enumerate(total_tickers, start=1):\n",
    "        try:\n",
    "            logger.info(f\"{i}/{len(total_tickers)} Processing: {ticker}\")\n",
    "            company = yf.Ticker(ticker)\n",
    "            process_price_history(company, ticker, db,first_date, last_date, logger)\n",
    "            process_dividends(company, ticker, db, logger)\n",
    "            process_splits(company, ticker, db, logger)\n",
    "            process_recommendations(company, ticker, db, logger)\n",
    "            if period=='monthly':\n",
    "                process_balance_sheet(company, ticker, db, logger)\n",
    "                process_financials(company, ticker, db, logger)\n",
    "                process_company_info(company, ticker, db, logger)\n",
    "                process_cashflow(company, ticker, db, logger)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"❌ Error en {ticker}: {e}\")\n",
    "            continue\n",
    "    end_time = datetime.now()            \n",
    "    elapsed_time = end_time - start_time\n",
    "    logger.info(f\"⏳ Total execution time: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d913fe4-7c5b-43a3-a035-e9694c08b16c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"first_date\", \"2025-04-05\", \"First Date\")\n",
    "dbutils.widgets.text(\"last_date\",  \"2025-04-10\", \"Last Date\")\n",
    "dbutils.widgets.text(\"period\",  \"daily\", \"Period\")\n",
    "\n",
    "first_date = dbutils.widgets.get(\"first_date\")\n",
    "last_date = dbutils.widgets.get(\"last_date\")\n",
    "period = dbutils.widgets.get(\"period\")\n",
    "print(f\"first_date: {first_date}, last_date: {last_date}\", period)\n",
    "\n",
    "main(first_date,last_date,period)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1_fetch_data_to_sql",
   "widgets": {
    "first_date": {
     "currentValue": "2025-04-10",
     "nuid": "9344e5ad-33bf-44f3-9630-1372bd3083e0",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2025-04-05",
      "label": "First Date",
      "name": "first_date",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2025-04-05",
      "label": "First Date",
      "name": "first_date",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "last_date": {
     "currentValue": "2025-04-11",
     "nuid": "e2fa798d-358e-48f8-9fb1-8785c190dd8c",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2025-04-10",
      "label": "Last Date",
      "name": "last_date",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2025-04-10",
      "label": "Last Date",
      "name": "last_date",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "period": {
     "currentValue": "daily",
     "nuid": "4723334f-193c-45f8-809d-730a7bd17431",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "daily",
      "label": "Period",
      "name": "period",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "daily",
      "label": "Period",
      "name": "period",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
